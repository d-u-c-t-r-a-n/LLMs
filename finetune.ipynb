{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1738597048551
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml import MLClient\n",
        "from azure.identity import (\n",
        "    DefaultAzureCredential,\n",
        "    InteractiveBrowserCredential,\n",
        ")\n",
        "import time\n",
        "\n",
        "from azure.ai.ml.dsl import pipeline\n",
        "from azure.ai.ml import Input\n",
        "\n",
        "import ast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def fetch_data(model_name):\n",
        "       import requests\n",
        "       import pandas as pd\n",
        "       from io import StringIO\n",
        "       from sklearn.model_selection import train_test_split\n",
        "       from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "       seed = 613\n",
        "\n",
        "       url = f\"\"\n",
        "       response = requests.get(url)\n",
        "\n",
        "       response.raise_for_status()\n",
        "\n",
        "       csv_data = StringIO(response.text)\n",
        "\n",
        "       df = pd.read_csv(csv_data)\n",
        "\n",
        "       test_size, val_size = .2, .2\n",
        "\n",
        "       train_df, temp_df = train_test_split(df, test_size=test_size + val_size, random_state=seed, stratify=df['label_string'])\n",
        "\n",
        "       val_size_adj = val_size / (val_size + test_size)\n",
        "       val_df, test_df = train_test_split(temp_df, test_size=1 - val_size_adj, random_state=seed, stratify=temp_df['label_string'])\n",
        "\n",
        "       train_df.to_json(\"train.jsonl\", orient='records', lines=True)\n",
        "       val_df.to_json(\"val.jsonl\", orient='records', lines=True)\n",
        "       test_df.to_json(\"test.jsonl\", orient='records', lines=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    credential = DefaultAzureCredential()\n",
        "    credential.get_token(\"https://management.azure.com/.default\")\n",
        "except Exception as ex:\n",
        "    credential = InteractiveBrowserCredential()\n",
        "\n",
        "subscription_id = ''\n",
        "resource_group_name = ''\n",
        "workspace_name = ''\n",
        "\n",
        "\n",
        "try:\n",
        "    workspace_ml_client = MLClient.from_config(credential=credential)\n",
        "except:\n",
        "    workspace_ml_client = MLClient(\n",
        "        credential,\n",
        "        subscription_id=subscription_id,\n",
        "        resource_group_name=resource_group_name,\n",
        "        workspace_name=workspace_name,\n",
        "    )\n",
        "\n",
        "# the models, fine tuning pipelines and environments are available in the AzureML system registry, \"azureml\"\n",
        "registry_ml_client = MLClient(credential, registry_name=\"azureml\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# define the pipeline job\n",
        "@pipeline()\n",
        "def create_pipeline():\n",
        "    text_classification_pipeline = pipeline_component_func(\n",
        "        # specify the foundation model available in the azureml system registry id identified in step #3\n",
        "        mlflow_model_path=foundation_model.id,\n",
        "        # huggingface_id = 'bert-base-uncased', # to use a huggingface model, uncomment this line and comment the above line\n",
        "        compute_model_import=compute_name,\n",
        "        compute_preprocess=compute_name,\n",
        "        compute_finetune=compute_name,\n",
        "        compute_model_evaluation=compute_name,\n",
        "        # map the dataset splits to parameters\n",
        "        train_file_path=Input(\n",
        "            type=\"uri_file\", path= \"./train.jsonl\"\n",
        "        ),\n",
        "        validation_file_path=Input(\n",
        "            type=\"uri_file\", path= \"val.jsonl\"\n",
        "        ),\n",
        "        test_file_path=Input(\n",
        "            type=\"uri_file\", path= \"./test.jsonl\"\n",
        "        ),\n",
        "        evaluation_config=Input(\n",
        "            type=\"uri_file\", path=\"./text-classification-config.json\"\n",
        "        ),\n",
        "        # The following parameters map to the dataset fields\n",
        "        sentence1_key=\"text\",\n",
        "        label_key=\"label_string\",\n",
        "        # Training settings\n",
        "        number_of_gpu_to_use_finetuning=gpus_per_node,  # set to the number of GPUs available in the compute\n",
        "        **training_parameters,\n",
        "        **optimization_parameters\n",
        "    )\n",
        "    return {\n",
        "        # map the output of the fine tuning job to the output of pipeline job so that we can easily register the fine tuned model\n",
        "        # registering the model is required to deploy the model to an online or batch endpoint\n",
        "        \"trained_model\": text_classification_pipeline.outputs.mlflow_model_folder\n",
        "    }"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3.10 - SDK v2",
      "language": "python",
      "name": "python310-sdkv2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
