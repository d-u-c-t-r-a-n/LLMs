{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1738597048551
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml import MLClient\n",
        "from azure.identity import (\n",
        "    DefaultAzureCredential,\n",
        "    InteractiveBrowserCredential,\n",
        ")\n",
        "import time\n",
        "\n",
        "from azure.ai.ml.dsl import pipeline\n",
        "from azure.ai.ml import Input\n",
        "\n",
        "import ast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def fetch_data(model_name):\n",
        "       import requests\n",
        "       import pandas as pd\n",
        "       from io import StringIO\n",
        "       from sklearn.model_selection import train_test_split\n",
        "       from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "       seed = 613\n",
        "\n",
        "       url = f\"\"\n",
        "       response = requests.get(url)\n",
        "\n",
        "       response.raise_for_status()\n",
        "\n",
        "       csv_data = StringIO(response.text)\n",
        "\n",
        "       df = pd.read_csv(csv_data)\n",
        "\n",
        "       test_size, val_size = .2, .2\n",
        "\n",
        "       train_df, temp_df = train_test_split(df, test_size=test_size + val_size, random_state=seed, stratify=df['label_string'])\n",
        "\n",
        "       val_size_adj = val_size / (val_size + test_size)\n",
        "       val_df, test_df = train_test_split(temp_df, test_size=1 - val_size_adj, random_state=seed, stratify=temp_df['label_string'])\n",
        "\n",
        "       train_df.to_json(\"train.jsonl\", orient='records', lines=True)\n",
        "       val_df.to_json(\"val.jsonl\", orient='records', lines=True)\n",
        "       test_df.to_json(\"test.jsonl\", orient='records', lines=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    credential = DefaultAzureCredential()\n",
        "    credential.get_token(\"https://management.azure.com/.default\")\n",
        "except Exception as ex:\n",
        "    credential = InteractiveBrowserCredential()\n",
        "\n",
        "subscription_id = ''\n",
        "resource_group_name = ''\n",
        "workspace_name = ''\n",
        "\n",
        "\n",
        "try:\n",
        "    workspace_ml_client = MLClient.from_config(credential=credential)\n",
        "except:\n",
        "    workspace_ml_client = MLClient(\n",
        "        credential,\n",
        "        subscription_id=subscription_id,\n",
        "        resource_group_name=resource_group_name,\n",
        "        workspace_name=workspace_name,\n",
        "    )\n",
        "\n",
        "# the models, fine tuning pipelines and environments are available in the AzureML system registry, \"azureml\"\n",
        "registry_ml_client = MLClient(credential, registry_name=\"azureml\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# define the pipeline job\n",
        "@pipeline()\n",
        "def create_pipeline():\n",
        "    text_classification_pipeline = pipeline_component_func(\n",
        "        # specify the foundation model available in the azureml system registry id identified in step #3\n",
        "        mlflow_model_path=foundation_model.id,\n",
        "        # huggingface_id = 'bert-base-uncased', # to use a huggingface model, uncomment this line and comment the above line\n",
        "        compute_model_import=compute_name,\n",
        "        compute_preprocess=compute_name,\n",
        "        compute_finetune=compute_name,\n",
        "        compute_model_evaluation=compute_name,\n",
        "        # map the dataset splits to parameters\n",
        "        train_file_path=Input(\n",
        "            type=\"uri_file\", path= \"./train.jsonl\"\n",
        "        ),\n",
        "        validation_file_path=Input(\n",
        "            type=\"uri_file\", path= \"val.jsonl\"\n",
        "        ),\n",
        "        test_file_path=Input(\n",
        "            type=\"uri_file\", path= \"./test.jsonl\"\n",
        "        ),\n",
        "        evaluation_config=Input(\n",
        "            type=\"uri_file\", path=\"./text-classification-config.json\"\n",
        "        ),\n",
        "        # The following parameters map to the dataset fields\n",
        "        sentence1_key=\"text\",\n",
        "        label_key=\"label_string\",\n",
        "        # Training settings\n",
        "        number_of_gpu_to_use_finetuning=gpus_per_node,  # set to the number of GPUs available in the compute\n",
        "        **training_parameters,\n",
        "        **optimization_parameters\n",
        "    )\n",
        "    return {\n",
        "        # map the output of the fine tuning job to the output of pipeline job so that we can easily register the fine tuned model\n",
        "        # registering the model is required to deploy the model to an online or batch endpoint\n",
        "        \"trained_model\": text_classification_pipeline.outputs.mlflow_model_folder\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "compute_name = \"Standard_NC12s_v3\"\n",
        "\n",
        "compute = workspace_ml_client.compute.get(compute_name)\n",
        "gpu_count_found = False\n",
        "workspace_compute_sku_list = workspace_ml_client.compute.list_sizes()\n",
        "available_sku_sizes = []\n",
        "for compute_sku in workspace_compute_sku_list:\n",
        "    available_sku_sizes.append(compute_sku.name)\n",
        "    if compute_sku.name.lower() == compute.size.lower():\n",
        "        gpus_per_node = compute_sku.gpus\n",
        "        gpu_count_found = True\n",
        "# if gpu_count_found not found, then print an error\n",
        "if gpu_count_found:\n",
        "    print(f\"Number of GPU's in compute {compute.size}: {gpus_per_node}\")\n",
        "else:\n",
        "    raise ValueError(\n",
        "        f\"Number of GPU's in compute {compute.size} not found. Available skus are: {available_sku_sizes}.\"\n",
        "        f\"This should not happen. Please check the selected compute cluster: {compute_name} and try again.\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "models = [\n",
        "    \"t5-small\", \n",
        "    \"t5-large\", \n",
        "    \"t5-base\", \n",
        "    \"microsoft-deberta-xlarge\", \n",
        "    \"microsoft-deberta-large-mnli\", \n",
        "    \"microsoft-deberta-large\", \n",
        "    \"microsoft-deberta-base-mnli\",\n",
        "    \"microsoft-deberta-base\",\n",
        "]\n",
        "\n",
        "for model_name in models:\n",
        "\n",
        "    fetch_data(model_name)\n",
        "    \n",
        "    experiment_name = \"text-classification-\" + model_name\n",
        "\n",
        "    foundation_model = registry_ml_client.models.get(model_name, label=\"latest\")\n",
        "\n",
        "    # Training parameters\n",
        "    training_parameters = dict(\n",
        "        num_train_epochs=5,\n",
        "        per_device_train_batch_size=4,\n",
        "        per_device_eval_batch_size=4,\n",
        "        learning_rate=2e-5,\n",
        "        metric_for_best_model=\"loss\",\n",
        "        resume_from_checkpoint=\"true\"\n",
        "    )\n",
        "    print(f\"The following training parameters are enabled - {training_parameters}\")\n",
        "\n",
        "    # Optimization parameters - As these parameters are packaged with the model itself, lets retrieve those parameters\n",
        "    if \"model_specific_defaults\" in foundation_model.tags:\n",
        "        optimization_parameters = ast.literal_eval(\n",
        "            foundation_model.tags[\"model_specific_defaults\"]\n",
        "        )  # convert string to python dict\n",
        "    else:\n",
        "        optimization_parameters = dict(\n",
        "            apply_lora=\"true\", \n",
        "            apply_deepspeed=\"true\", \n",
        "            apply_ort=\"true\"\n",
        "        )\n",
        "    print(f\"The following optimizations are enabled - {optimization_parameters}\")\n",
        "\n",
        "    # fetch the pipeline component\n",
        "    pipeline_component_func = registry_ml_client.components.get(\n",
        "        name=\"text_classification_pipeline\", \n",
        "        label=\"latest\"\n",
        "    )\n",
        "    \n",
        "    pipeline_object = create_pipeline()\n",
        "\n",
        "    # don't use cached results from previous jobs\n",
        "    pipeline_object.settings.force_rerun = True\n",
        "\n",
        "    # set continue on step failure to False\n",
        "    pipeline_object.settings.continue_on_step_failure = False\n",
        "\n",
        "    # submit the pipeline job\n",
        "    pipeline_job = workspace_ml_client.jobs.create_or_update(\n",
        "        pipeline_object, experiment_name=experiment_name\n",
        "    )"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3.10 - SDK v2",
      "language": "python",
      "name": "python310-sdkv2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
